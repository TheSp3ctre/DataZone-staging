# üìä Guia de Processamento de Dados

## Scripts Criados

Foram criados 3 scripts profissionais para processar dados:

### 1. `process_aneel_subestacoes.py`
- **Fonte**: Arquivos Geodatabase (.gdb) da ANEEL
- **Destino**: Tabela `geo.subestacoes`
- **Funcionalidades**:
  - L√™ arquivos .gdb
  - Detecta automaticamente a camada de subesta√ß√µes
  - Valida e corrige geometrias inv√°lidas
  - Converte CRS para EPSG:4326
  - Remove duplicatas
  - Gera estat√≠sticas por UF e faixa de tens√£o

### 2. `process_aneel_linhas.py`
- **Fonte**: Arquivos Geodatabase (.gdb) da ANEEL
- **Destino**: Tabela `geo.linhas_transmissao`
- **Funcionalidades**:
  - Processa linhas de transmiss√£o (LineString)
  - Calcula extens√£o em km automaticamente
  - Valida√ß√£o completa de geometrias
  - Estat√≠sticas por tens√£o e extens√£o total

### 3. `process_anatel_fibra.py`
- **Fonte**: Arquivos CSV da ANATEL
- **Destino**: Tabela `geo.fibra_optica`
- **Funcionalidades**:
  - L√™ CSV com m√∫ltiplos encodings
  - Cria geometrias Point a partir de lat/lon
  - Valida coordenadas
  - Estat√≠sticas por UF e operadora

---

## üöÄ Como Usar

### Passo 1: Obter os Dados

#### ANEEL (Geodatabase)
1. Acesse: https://dadosabertos.aneel.gov.br/
2. Baixe os arquivos de:
   - Subesta√ß√µes
   - Linhas de Transmiss√£o
3. Coloque os arquivos `.gdb` em `data/raw/`

#### ANATEL (CSV)
1. Acesse: https://www.anatel.gov.br/dados-abertos/
2. Baixe dados de infraestrutura de telecomunica√ß√µes
3. Coloque os arquivos `.csv` em `data/raw/`

---

### Passo 2: Executar os Scripts

#### Dentro do Container Docker (Recomendado)

```powershell
# Processar subesta√ß√µes
docker-compose exec api python scripts/process_aneel_subestacoes.py

# Processar linhas de transmiss√£o
docker-compose exec api python scripts/process_aneel_linhas.py

# Processar fibra √≥tica
docker-compose exec api python scripts/process_anatel_fibra.py
```

#### Localmente (se tiver Python instalado)

```powershell
# Ativar ambiente virtual (se tiver)
# .\.venv\Scripts\Activate.ps1

# Executar scripts
python scripts/process_aneel_subestacoes.py
python scripts/process_aneel_linhas.py
python scripts/process_anatel_fibra.py
```

---

### Passo 3: Ajustar os Scripts

**IMPORTANTE**: Voc√™ precisar√° ajustar os scripts conforme a estrutura real dos seus arquivos!

#### Ajustes Necess√°rios:

1. **Caminho dos arquivos** (em cada script, fun√ß√£o `main()`):
   ```python
   # AJUSTAR ESTES CAMINHOS:
   gdb_path = "data/raw/SEU_ARQUIVO.gdb"
   csv_path = "data/raw/SEU_ARQUIVO.csv"
   ```

2. **Nomes das colunas** (mapear colunas do arquivo para o banco):
   ```python
   column_mapping = {
       'NOME_COLUNA_ARQUIVO': 'nome_coluna_banco',
       # Exemplo:
       'NOM_SE': 'nome',
       'COD_SE': 'codigo',
       'TEN_NOM': 'tensao_kv',
   }
   ```

3. **Nome da camada** (para arquivos .gdb):
   ```python
   # Se a detec√ß√£o autom√°tica n√£o funcionar:
   layer_name = "nome_exato_da_camada"
   ```

---

## üîç Verificar Dados Processados

### Via psql

```powershell
# Conectar ao banco
docker-compose exec postgis psql -U datazone_user -d datazone_energy

# Dentro do psql:
# Contar registros
SELECT COUNT(*) FROM geo.subestacoes;
SELECT COUNT(*) FROM geo.linhas_transmissao;
SELECT COUNT(*) FROM geo.fibra_optica;

# Ver primeiros registros
SELECT * FROM geo.subestacoes LIMIT 5;

# Estat√≠sticas por UF
SELECT uf, COUNT(*) as total 
FROM geo.subestacoes 
GROUP BY uf 
ORDER BY total DESC;

# Sair
\q
```

### Via API

```powershell
# Testar endpoints
curl http://localhost:8000/api/v1/subestacoes?limit=10
curl http://localhost:8000/api/v1/linhas?limit=10
curl http://localhost:8000/api/v1/fibra?limit=10
```

---

## üìù Logs

Os scripts geram logs em:
- **Console**: Output colorido em tempo real
- **Arquivo**: `logs/process_*.log` (rota√ß√£o di√°ria, mant√©m 30 dias)

---

## üêõ Troubleshooting

### Erro: "Arquivo n√£o encontrado"
```
‚úÖ Solu√ß√£o: Verificar caminho do arquivo no script
```

### Erro: "Camada n√£o encontrada"
```
‚úÖ Solu√ß√£o: Listar camadas dispon√≠veis:
python -c "import fiona; print(fiona.listlayers('data/raw/arquivo.gdb'))"
```

### Erro: "Coluna n√£o existe"
```
‚úÖ Solu√ß√£o: Ver colunas dispon√≠veis:
import geopandas as gpd
gdf = gpd.read_file('arquivo.gdb', layer='camada')
print(gdf.columns)
```

### Erro: "CRS inv√°lido"
```
‚úÖ Solu√ß√£o: O script converte automaticamente para EPSG:4326
Se persistir, verificar CRS original:
print(gdf.crs)
```

---

## üìä Exemplo de Output

```
================================================================================
PROCESSAMENTO DE SUBESTA√á√ïES - ANEEL
================================================================================
Arquivo GDB: data/raw/aneel_subestacoes.gdb
Camadas dispon√≠veis: ['subestacoes', 'outras_camadas']
Usando camada: subestacoes
Lendo dados...
Colunas dispon√≠veis: ['nome', 'codigo', 'tensao_kv', 'uf', 'geometry']
Tipo de geometria: ['Point']
Validando subestacoes...
Registros originais: 1500
Convertendo CRS de EPSG:31983 para EPSG:4326...
Registros ap√≥s valida√ß√£o: 1498 (2 removidos)
Conectando ao banco de dados...
Inserindo dados no PostGIS...
‚úÖ 1498 subesta√ß√µes inseridas com sucesso!

================================================================================
ESTAT√çSTICAS
================================================================================

Distribui√ß√£o por UF:
  SP: 450
  MG: 320
  RJ: 280
  ...

Distribui√ß√£o por faixa de tens√£o:
  138-230kV: 600
  230-500kV: 450
  ...
```

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ Baixar dados da ANEEL e ANATEL
2. ‚úÖ Colocar arquivos em `data/raw/`
3. ‚úÖ Ajustar caminhos nos scripts
4. ‚úÖ Executar scripts de processamento
5. ‚úÖ Verificar dados no banco
6. ‚úÖ Testar endpoints da API
7. ‚è≥ Criar GitHub Actions para CI/CD
8. ‚è≥ Deploy no Railway
